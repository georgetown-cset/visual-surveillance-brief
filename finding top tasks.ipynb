{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload csv of computer vision papers with tagged tasks\n",
    "paper_df = pd.read_csv('data/cv_matched_tasks_methods.csv')\n",
    "\n",
    "#make paper tasks lowercase\n",
    "## improves our count of unique tasks\n",
    "## our regexmatching ignores case anyway, though\n",
    "paper_df[\"tasks\"] = paper_df[\"tasks\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cset_id</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>tasks</th>\n",
       "      <th>methods</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carticle_0036993254</td>\n",
       "      <td>2016</td>\n",
       "      <td>China</td>\n",
       "      <td>{'no-reference quality assessment of enhanced ...</td>\n",
       "      <td>set()</td>\n",
       "      <td>No-reference quality assessment of enhanced im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carticle_0169019068</td>\n",
       "      <td>2017</td>\n",
       "      <td>Australia</td>\n",
       "      <td>set()</td>\n",
       "      <td>{'convolutional neural networks'}</td>\n",
       "      <td>Beyond filters: compact feature map for portab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>carticle_0082207762</td>\n",
       "      <td>2017</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>{'dimensionality reduction'}</td>\n",
       "      <td>{'Semi-supervised double sparse graphs'}</td>\n",
       "      <td>Semi-supervised double sparse graphs based dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carticle_0063791730</td>\n",
       "      <td>2018</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>{'moving object in 3-dimensional space', 'desi...</td>\n",
       "      <td>{'Genetic Algorithm'}</td>\n",
       "      <td>Designing an Optimization of Orientation Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>carticle_0076183469</td>\n",
       "      <td>2016</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>{'object detection'}</td>\n",
       "      <td>{'primitive BG model-based'}</td>\n",
       "      <td>Robust techniques for abandoned and removed ob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cset_id  year      country  \\\n",
       "0  carticle_0036993254  2016        China   \n",
       "1  carticle_0169019068  2017    Australia   \n",
       "2  carticle_0082207762  2017  New Zealand   \n",
       "3  carticle_0063791730  2018    Indonesia   \n",
       "4  carticle_0076183469  2016       Taiwan   \n",
       "\n",
       "                                               tasks  \\\n",
       "0  {'no-reference quality assessment of enhanced ...   \n",
       "1                                              set()   \n",
       "2                       {'dimensionality reduction'}   \n",
       "3  {'moving object in 3-dimensional space', 'desi...   \n",
       "4                               {'object detection'}   \n",
       "\n",
       "                                    methods  \\\n",
       "0                                     set()   \n",
       "1         {'convolutional neural networks'}   \n",
       "2  {'Semi-supervised double sparse graphs'}   \n",
       "3                     {'Genetic Algorithm'}   \n",
       "4              {'primitive BG model-based'}   \n",
       "\n",
       "                                                text  \n",
       "0  No-reference quality assessment of enhanced im...  \n",
       "1  Beyond filters: compact feature map for portab...  \n",
       "2  Semi-supervised double sparse graphs based dis...  \n",
       "3  Designing an Optimization of Orientation Syste...  \n",
       "4  Robust techniques for abandoned and removed ob...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208867, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying top tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_row_tasks_all(paper_df):\n",
    "    \"\"\"generate the list of tasks for each row.\n",
    "        row_tasks_all = list of lists of tasks\n",
    "        task_counts = each paper's number of tasks\n",
    "        unique_tasks = list of unique tasks\n",
    "    \"\"\"\n",
    "    task_counts = []\n",
    "    row_tasks_all = []\n",
    "    task_list = []\n",
    "    for row in range(len(paper_df)):\n",
    "        row_tasks = eval(paper_df.iloc[row]['tasks'])        \n",
    "        row_tasks_all.append(row_tasks)\n",
    "        for task in row_tasks:\n",
    "            task_list.append(task)\n",
    "        n_tasks = len(row_tasks)\n",
    "        task_counts.append(n_tasks)\n",
    "    unique_tasks = list(set(task_list))\n",
    "    return row_tasks_all, task_counts, unique_tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_tasks_all, task_counts, unique_tasks = gen_row_tasks_all(paper_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = list(paper_df['country']) #list all countries which have at least one computer vision paper\n",
    "n_papers = len(row_tasks_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate overall statistics -- what are the most popular tasks?\n",
    "\n",
    "def gen_task_counts(row_tasks_all, unique_tasks):\n",
    "    task_counts = {}\n",
    "    for curr_tasks in row_tasks_all:\n",
    "        for task in curr_tasks:\n",
    "            try: task_counts[task] += 1\n",
    "            except: task_counts[task] = 1\n",
    "    return task_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_counts = gen_task_counts(row_tasks_all, unique_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe with top tasks by paper count and percentage of CV papers they appear in\n",
    "task_count_df = pd.DataFrame.from_dict(task_counts, orient='index', columns = ['count'])\n",
    "task_count_df.insert(1, 'percentage', [ct*100./n_papers for ct in task_count_df['count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>object detection</th>\n",
       "      <td>7282</td>\n",
       "      <td>3.486429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image classification</th>\n",
       "      <td>7262</td>\n",
       "      <td>3.476854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face recognition</th>\n",
       "      <td>5997</td>\n",
       "      <td>2.871205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>denoising</th>\n",
       "      <td>4410</td>\n",
       "      <td>2.111391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image retrieval</th>\n",
       "      <td>3629</td>\n",
       "      <td>1.737469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object recognition</th>\n",
       "      <td>3480</td>\n",
       "      <td>1.666132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pose estimation</th>\n",
       "      <td>2984</td>\n",
       "      <td>1.428660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semantic segmentation</th>\n",
       "      <td>2829</td>\n",
       "      <td>1.354450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action recognition</th>\n",
       "      <td>2727</td>\n",
       "      <td>1.305616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super-resolution</th>\n",
       "      <td>2680</td>\n",
       "      <td>1.283113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count  percentage\n",
       "object detection        7282    3.486429\n",
       "image classification    7262    3.476854\n",
       "face recognition        5997    2.871205\n",
       "denoising               4410    2.111391\n",
       "image retrieval         3629    1.737469\n",
       "object recognition      3480    1.666132\n",
       "pose estimation         2984    1.428660\n",
       "semantic segmentation   2829    1.354450\n",
       "action recognition      2727    1.305616\n",
       "super-resolution        2680    1.283113"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list the top 10 tasks\n",
    "task_count_df.sort_values('count', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks with the highest difference in US vs Chinese focus\n",
    "We list tasks by the proportion of US and Chinese papers they appear in, and find the tasks with the largest difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_country_task_counts(row_tasks_all, unique_tasks, country_list):\n",
    "    \"\"\"\n",
    "    takes in: a list, each element of which is a list of the tasks belonging to a paper (row_tasks_all)\n",
    "    a list of unique tasks\n",
    "    a list of all countries\n",
    "    Generates a dictionary, country_task_counts, whose keys are country strings: \n",
    "    For each country, country_task_counts[country] is a dictionary whose keys are tasks and whose values are the number of country papers in which that task occurs\n",
    "    note: to allow intercountry comparison, we generate {task, 0} pairs for tasks that don't appear in any of a country's papers\n",
    "    \"\"\"\n",
    "    \n",
    "    country_task_counts = {}\n",
    "    for country in set(country_list):\n",
    "        country_task_counts[country] = {}\n",
    "        for task in unique_tasks:\n",
    "            country_task_counts[country][task] = 0\n",
    "    \n",
    "    for i in range(len(row_tasks_all)):\n",
    "        curr_country = country_list[i]\n",
    "        ct = row_tasks_all[i]\n",
    "        for task in ct:\n",
    "            try: country_task_counts[curr_country][task] += 1\n",
    "            except: task_counts[curr_country][task] = 1\n",
    "    return country_task_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_task_counts = gen_country_task_counts(row_tasks_all, unique_tasks, country_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_counts = country_task_counts[\"United States\"]\n",
    "CH_counts = country_task_counts[\"China\"]\n",
    "\n",
    "n_US = country_list.count(\"United States\")\n",
    "n_CH = country_list.count(\"China\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_count_df = pd.DataFrame.from_dict(US_counts, orient='index', columns = ['count'])\n",
    "US_count_df.insert(1, 'percent_country', [ct*100./n_US for ct in US_count_df['count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH_count_df = pd.DataFrame.from_dict(CH_counts, orient='index', columns = ['count'])\n",
    "CH_count_df.insert(1, 'percent_country', [ct*100./n_CH for ct in CH_count_df['count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each task, find the difference in \"% of US papers that include the task\" and \"% of CH papers that include the task\"\n",
    "US_CH_pct_diffs = {}\n",
    "for task in unique_tasks:\n",
    "    US_pct = US_count_df.loc[task]['percent_country']\n",
    "    CH_pct = CH_count_df.loc[task]['percent_country']\n",
    "    US_minus_CH_pct = US_pct-CH_pct\n",
    "    US_count = US_count_df.loc[task]['count']\n",
    "    CH_count = CH_count_df.loc[task]['count']\n",
    "    world_count = task_count_df.loc[task]['count']\n",
    "    world_pct = task_count_df.loc[task]['percentage']\n",
    "    \n",
    "    US_CH_pct_diffs[task] = [US_minus_CH_pct, US_count, CH_count, world_count, US_pct, CH_pct, world_pct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataframe of tasks with US-CH differences\n",
    "US_CH_diffs_df = pd.DataFrame.from_dict(US_CH_pct_diffs, orient='index', columns = ['US-CH percent difference', 'US count', 'CH count', 'world count', 'US pct', 'CH pct', 'percent of world'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US-CH percent difference</th>\n",
       "      <th>US count</th>\n",
       "      <th>CH count</th>\n",
       "      <th>world count</th>\n",
       "      <th>US pct</th>\n",
       "      <th>CH pct</th>\n",
       "      <th>percent of world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>object recognition</th>\n",
       "      <td>0.983376</td>\n",
       "      <td>775.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>2.125326</td>\n",
       "      <td>1.141950</td>\n",
       "      <td>1.666132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computed tomography (ct)</th>\n",
       "      <td>0.797431</td>\n",
       "      <td>454.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>1.245029</td>\n",
       "      <td>0.447598</td>\n",
       "      <td>0.753111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semantic segmentation</th>\n",
       "      <td>0.589970</td>\n",
       "      <td>672.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>2829.0</td>\n",
       "      <td>1.842863</td>\n",
       "      <td>1.252893</td>\n",
       "      <td>1.354450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfer learning</th>\n",
       "      <td>0.566128</td>\n",
       "      <td>581.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>1.593309</td>\n",
       "      <td>1.027181</td>\n",
       "      <td>1.190710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pose estimation</th>\n",
       "      <td>0.538236</td>\n",
       "      <td>635.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>2984.0</td>\n",
       "      <td>1.741396</td>\n",
       "      <td>1.203160</td>\n",
       "      <td>1.428660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activity recognition</th>\n",
       "      <td>0.440378</td>\n",
       "      <td>268.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.734951</td>\n",
       "      <td>0.294573</td>\n",
       "      <td>0.629587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question answering</th>\n",
       "      <td>0.349470</td>\n",
       "      <td>193.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>0.529275</td>\n",
       "      <td>0.179805</td>\n",
       "      <td>0.223108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision making</th>\n",
       "      <td>0.312600</td>\n",
       "      <td>167.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.457973</td>\n",
       "      <td>0.145374</td>\n",
       "      <td>0.373922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain adaptation</th>\n",
       "      <td>0.311156</td>\n",
       "      <td>299.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>0.819964</td>\n",
       "      <td>0.508809</td>\n",
       "      <td>0.514203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scene understanding</th>\n",
       "      <td>0.306695</td>\n",
       "      <td>206.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>0.564925</td>\n",
       "      <td>0.258230</td>\n",
       "      <td>0.383498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          US-CH percent difference  US count  CH count  \\\n",
       "object recognition                        0.983376     775.0     597.0   \n",
       "computed tomography (ct)                  0.797431     454.0     234.0   \n",
       "semantic segmentation                     0.589970     672.0     655.0   \n",
       "transfer learning                         0.566128     581.0     537.0   \n",
       "pose estimation                           0.538236     635.0     629.0   \n",
       "activity recognition                      0.440378     268.0     154.0   \n",
       "question answering                        0.349470     193.0      94.0   \n",
       "decision making                           0.312600     167.0      76.0   \n",
       "domain adaptation                         0.311156     299.0     266.0   \n",
       "scene understanding                       0.306695     206.0     135.0   \n",
       "\n",
       "                          world count    US pct    CH pct  percent of world  \n",
       "object recognition             3480.0  2.125326  1.141950          1.666132  \n",
       "computed tomography (ct)       1573.0  1.245029  0.447598          0.753111  \n",
       "semantic segmentation          2829.0  1.842863  1.252893          1.354450  \n",
       "transfer learning              2487.0  1.593309  1.027181          1.190710  \n",
       "pose estimation                2984.0  1.741396  1.203160          1.428660  \n",
       "activity recognition           1315.0  0.734951  0.294573          0.629587  \n",
       "question answering              466.0  0.529275  0.179805          0.223108  \n",
       "decision making                 781.0  0.457973  0.145374          0.373922  \n",
       "domain adaptation              1074.0  0.819964  0.508809          0.514203  \n",
       "scene understanding             801.0  0.564925  0.258230          0.383498  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the tasks with highest \"US% - CH%\"\n",
    "US_CH_diffs_df.sort_values('US-CH percent difference', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US-CH percent difference</th>\n",
       "      <th>US count</th>\n",
       "      <th>CH count</th>\n",
       "      <th>world count</th>\n",
       "      <th>US pct</th>\n",
       "      <th>CH pct</th>\n",
       "      <th>percent of world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>saliency detection</th>\n",
       "      <td>-1.114955</td>\n",
       "      <td>134.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>0.367476</td>\n",
       "      <td>1.482431</td>\n",
       "      <td>0.601340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super-resolution</th>\n",
       "      <td>-1.029209</td>\n",
       "      <td>408.0</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>1.118881</td>\n",
       "      <td>2.148090</td>\n",
       "      <td>1.283113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image classification</th>\n",
       "      <td>-0.997594</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>2338.0</td>\n",
       "      <td>7262.0</td>\n",
       "      <td>3.474565</td>\n",
       "      <td>4.472159</td>\n",
       "      <td>3.476854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visual tracking</th>\n",
       "      <td>-0.964223</td>\n",
       "      <td>235.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>0.644454</td>\n",
       "      <td>1.608677</td>\n",
       "      <td>0.766995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>denoising</th>\n",
       "      <td>-0.828967</td>\n",
       "      <td>654.0</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>1.793501</td>\n",
       "      <td>2.622468</td>\n",
       "      <td>2.111391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face recognition</th>\n",
       "      <td>-0.797951</td>\n",
       "      <td>892.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>5997.0</td>\n",
       "      <td>2.446181</td>\n",
       "      <td>3.244132</td>\n",
       "      <td>2.871205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image super-resolution</th>\n",
       "      <td>-0.769477</td>\n",
       "      <td>170.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>0.466200</td>\n",
       "      <td>1.235678</td>\n",
       "      <td>0.588413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object tracking</th>\n",
       "      <td>-0.737856</td>\n",
       "      <td>358.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>2597.0</td>\n",
       "      <td>0.981763</td>\n",
       "      <td>1.719620</td>\n",
       "      <td>1.243375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image denoising</th>\n",
       "      <td>-0.698342</td>\n",
       "      <td>235.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>1904.0</td>\n",
       "      <td>0.644454</td>\n",
       "      <td>1.342795</td>\n",
       "      <td>0.911585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person re-identification</th>\n",
       "      <td>-0.653147</td>\n",
       "      <td>218.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>0.597834</td>\n",
       "      <td>1.250980</td>\n",
       "      <td>0.661665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          US-CH percent difference  US count  CH count  \\\n",
       "saliency detection                       -1.114955     134.0     775.0   \n",
       "super-resolution                         -1.029209     408.0    1123.0   \n",
       "image classification                     -0.997594    1267.0    2338.0   \n",
       "visual tracking                          -0.964223     235.0     841.0   \n",
       "denoising                                -0.828967     654.0    1371.0   \n",
       "face recognition                         -0.797951     892.0    1696.0   \n",
       "image super-resolution                   -0.769477     170.0     646.0   \n",
       "object tracking                          -0.737856     358.0     899.0   \n",
       "image denoising                          -0.698342     235.0     702.0   \n",
       "person re-identification                 -0.653147     218.0     654.0   \n",
       "\n",
       "                          world count    US pct    CH pct  percent of world  \n",
       "saliency detection             1256.0  0.367476  1.482431          0.601340  \n",
       "super-resolution               2680.0  1.118881  2.148090          1.283113  \n",
       "image classification           7262.0  3.474565  4.472159          3.476854  \n",
       "visual tracking                1602.0  0.644454  1.608677          0.766995  \n",
       "denoising                      4410.0  1.793501  2.622468          2.111391  \n",
       "face recognition               5997.0  2.446181  3.244132          2.871205  \n",
       "image super-resolution         1229.0  0.466200  1.235678          0.588413  \n",
       "object tracking                2597.0  0.981763  1.719620          1.243375  \n",
       "image denoising                1904.0  0.644454  1.342795          0.911585  \n",
       "person re-identification       1382.0  0.597834  1.250980          0.661665  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list the tasks with lowest \"US% - CH%\"\n",
    "US_CH_diffs_df.sort_values('US-CH percent difference', ascending=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
